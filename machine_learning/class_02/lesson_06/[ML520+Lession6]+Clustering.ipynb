{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Clustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group and dissimilar to the data points in other groups.\n",
    "\n",
    "In this assignment, we will explore two clustering algorithms: k-means and hierachical clustering. Also, you will apply k-means on two real world applications: handwritten digit regconition and image compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from IPython.display import display \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "K-means algorithm partitions the input data into K clusters by iterating between the following two steps:\n",
    "\n",
    "- Computer the cluster center by computing the arithmetic mean of all the points belonging to the cluster.\n",
    "- Assign each point to the closest cluster center.\n",
    "\n",
    "To see how k-means algorithm works, we first generate some synthetic dataset where we pre-define 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=1)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Apply [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) API from sklearn on this synthetic data and if it can accurate cluster this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# TODO\n",
    "kmeans = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the partitioned dataset together with its cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "Hierarchical Clustering is another very popular clustering algorithm. Unlike k-means, it also provides a hierarchy of clusters.\n",
    "\n",
    "**TODO**: apply hierarchical clustering to cluster this dataset using [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) and then generate the scatter plot of the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Generate the dendrogram using [dendrogram](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html) function and [linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html) function for this dataset. Can you tell what's the right number of clusters from the dendrogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Digits\n",
    "\n",
    "Now you are familiar with the k-means API and applied it on a small synthetic dataset. Now let's see how we can apply k-means algorithm to help use clssify handwritten digits without labels being provided.\n",
    "\n",
    "We will use the digits from sklearn datsets and apply k-means clustering algorithm. Each digit image consists of 64 features where each feature indicates the brightness of one pixel in an 8Ã—8 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape\n",
    "\n",
    "# the label of each image\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Perform K-means with the number of clusters of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is 10 clusters in 64 dimensions where each cluster center is a 64-dimensional point and can be interpreted as the \"typical\" digit within the cluster. We can visualize the cluster center with the following code.\n",
    "\n",
    "If you did the k-means clustering correctly, you should easily recognize the digits in each cluster. It's pretty amazing that we can cluster majority of the images into the right category without the explicit labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n",
    "centers = kmeans.cluster_centers_.reshape(10, 8, 8)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Can you evaluate the prediction accuracy of the k-means model by comparing with the ground truth? Also, try to find out which two digits are most likely to be confused with each other.\n",
    "\n",
    "Hint: you can use the label from majority of the data in a cluster and assign that label to all data points within that cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Compression\n",
    "\n",
    "Color compression within images is another interesting application where you can apply clustering techniques to reduce the storage of images without necessarily impact its visualization. If you have an image with millions of colors, very likely many of the pixels in the image will have similar or even identical colors, so you can use assign the same color to all pixels close by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: this requires the ``pillow`` package to be installed\n",
    "from sklearn.datasets import load_sample_image\n",
    "flower = load_sample_image(\"flower.jpg\")\n",
    "print(flower.shape)\n",
    "\n",
    "# display the image\n",
    "ax = plt.axes(xticks=[], yticks=[])\n",
    "ax.imshow(flower)\n",
    "\n",
    "# preprocess the data\n",
    "data = flower / 255.0 # use 0...1 scale\n",
    "data = data.reshape(427 * 640, 3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: This image above has over 16 million colors (do you know why it's 16 million?). In this task, use [MiniBatchKMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html) to cluster the flower image and reduce the number of colors to 64 using the k-means clustering. \n",
    "\n",
    "Hint: due to the number of pixels in the image, we can use the mini batch k-means(i.e. MiniBatchKMeans) to speed up the k-means algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# TODO\n",
    "K = 64\n",
    "kmeans = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we apply the clustering algorithm to the flower image, the following code puts the original image and the  re-colored one side-by-side. In the re-colored image, each pixel is assigned the color of its closest cluster center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flower_recolored = new_colors.reshape(flower.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6),\n",
    "                       subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "ax[0].imshow(flower)\n",
    "ax[0].set_title('Original Image', size=16)\n",
    "ax[1].imshow(flower_recolored)\n",
    "ax[1].set_title('{}-color Image'.format(K), size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of the details in the image are missing, but it does not significantly impact the quality of the image, but we reduce the number of colors in the image and thus its size to store it. You can play around with different number of K to balance between the quality and the size of the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
