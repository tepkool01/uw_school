{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System\n",
    "\n",
    "In this lab, we will use a python package named [Surprise](http://surpriselib.com/), which is an easy-to-use Python scikit for recommendation systems. It includes several commonly used algorithms, including [collaborative filtering](https://surprise.readthedocs.io/en/stable/knn_inspired.html) and [Matrix Factorization-based algorithms](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # install packages\n",
    "# import sys\n",
    "\n",
    "# !pip3 install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from surprise.prediction_algorithms.knns import KNNWithMeans\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from package surprise \n",
    "\n",
    "First, we can download the ml-100k dataset included in package surprise. The data will be saved in the .surprise_data folder in your home directory. Use the API in the package to sample random trainset and testset where test set is made of 20% of the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the movielens-100k dataset (download it if needed) and split the data into \n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# TODO: sample random trainset and testset where test set is made of 20% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1651\n",
      "Number of ratings: 80000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users: {}\".format(trainset.n_users))\n",
    "print(\"Number of items: {}\".format(trainset.n_items))\n",
    "print(\"Number of ratings: {}\".format(trainset.n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "First, we will apply three different flavors of collaborative filtering to this data and evaluate their performances using RMSE and MAE. For each of these algorithms, the actual number of neighbors that are aggregated to compute an estimation is necessarily less than or equal to `ùëò`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basic collaborative filtering algorithm\n",
    "\n",
    "**TODO**: You will study the [KNNBasic](https://surprise.readthedocs.io/en/stable/knn_inspired.html) API, choose the number of neighbors and the similarity measure, train the model based on training dataset and make predictions on the test dataset. Finally, you will evaluate the model performance based on RMSE and MAE. \n",
    "\n",
    "Try to play around with the different number of neighbors in the algorithm as well as the different similarity measure and see how it impacts the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9777\n",
      "MAE:  0.7722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7722053260122412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the basic collaborative filtering algorithm. \n",
    "# See https://surprise.readthedocs.io/en/stable/knn_inspired.html for more details.\n",
    "cf = KNNBasic()\n",
    "cf.fit(trainset)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "predictions = cf.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basic collaborative filtering algorithm with user mean ratings\n",
    "\n",
    "**TODO**: A variation of the basic CF model is to take into account the mean ratings of each user. You will study the [KNNWithMeans](https://surprise.readthedocs.io/en/stable/knn_inspired.html) API, choose the number of neighbors and the similarity measure, train the model based on training dataset and make predictions on the test dataset. Finally, you will evaluate the model performance based on RMSE and MAE. \n",
    "\n",
    "Try to play around with the different number of neighbors in the algorithm as well as the different similarity measure and see how it impacts the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9453\n",
      "MAE:  0.7448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7447854992381883"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "# See https://surprise.readthedocs.io/en/stable/knn_inspired.html for more details.\n",
    "cf_mean = KNNWithMeans()\n",
    "cf_mean.fit(trainset)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "predictions = cf_mean.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "Then, we will explore the matrix factorization techniques for recommendation. Matrix factorization algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices. The famous SVD algorithm for matrix factorization is popularized by Simon Funk during the Netflix Prize. \n",
    "\n",
    "**TODO**: in this task, you will use the famous SVD algorithm for the implementation of the matrix factorization modeo. You will study the [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) API, choose the number of neighbors and the similarity measure, train the model based on training dataset and make predictions on the test dataset. Finally, you will evaluate the model performance based on RMSE and MAE. \n",
    "\n",
    "Try to play around with different number of factors and also try the [SVD++ algorithm](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) and [Non-negative Matrix Factorization](https://surprise.readthedocs.io/en/stable/matrix_factorization.html) to see if you can imporve the model preformance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9295\n",
      "MAE:  0.7329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7329421166098867"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "svd = SVD(n_factors=20)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BONUS] \n",
    "Implement your own version of User-User or Item-Item Collaborative Filtering and compare its performance against the surprise package's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Lab: Recommendation System"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
