{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 9: Bayesian Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.1 Explain in few terms what is Naive Bayes. What is it considered Naive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive bayes is a classification algorithm based on the Baye's theorem, which has conditional probability built in and prior beliefs.\n",
    "# It is called naive because it assumes that all the predictors are independent of one another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1841 entries, 0 to 1840\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Rash                     1841 non-null   object\n",
      " 1   SwollenLymphNode         1841 non-null   object\n",
      " 2   Chills                   1841 non-null   object\n",
      " 3   PolymeraseChainReaction  1841 non-null   object\n",
      " 4   VZVAntibodyTest          1841 non-null   object\n",
      " 5   Blisters                 1841 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 86.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Rash SwollenLymphNode Chills PolymeraseChainReaction VZVAntibodyTest  \\\n0   no               no     no                      no             pos   \n1  yes               no     no                      no             neg   \n2   no               no     no                      no             neg   \n3   no               no     no                      no             neg   \n4   no               no     no                      no             neg   \n\n  Blisters  \n0       no  \n1       no  \n2       no  \n3       no  \n4       no  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rash</th>\n      <th>SwollenLymphNode</th>\n      <th>Chills</th>\n      <th>PolymeraseChainReaction</th>\n      <th>VZVAntibodyTest</th>\n      <th>Blisters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>pos</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>yes</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>neg</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>neg</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>neg</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>neg</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('shingles.csv')\n",
    "print(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.2. Does this data contain any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "data.isna().sum()\n",
    "print(\"No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.3. Split the data into 70/30 train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Converting text values to numeric for models\n",
    "data.replace(\"yes\", 1, inplace=True)\n",
    "data.replace(\"no\", 0, inplace=True)\n",
    "data.replace(\"pos\", 1, inplace=True)\n",
    "data.replace(\"po\", 1, inplace=True) # found this value and am interpretting it to be a typo meaning 'pos'\n",
    "data.replace(\"neg\", 0, inplace=True)\n",
    "\n",
    "y = data[\"Rash\"]\n",
    "X = data.drop(\"Rash\", axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.4. Train a Gaussian Naive Bayes model, a Multinomial Naive Bayes and a Bernoulli Naive Bayes on the dataset to predict Rash. Compute the accuracy for each. Explain your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli score: 0.5135623869801085\n",
      "Gaussian score: 0.5117540687160941\n",
      "Multinomial score: 0.5334538878842676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "BernNB = BernoulliNB()\n",
    "BernNB.fit(X_train, y_train)\n",
    "y_pred = BernNB.predict(X_test)\n",
    "print(\"Bernoulli score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "GausNB = GaussianNB()\n",
    "GausNB.fit(X_train, y_train)\n",
    "y_pred = GausNB.predict(X_test)\n",
    "print(\"Gaussian score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "y_pred = MultiNB.predict(X_test)\n",
    "print(\"Multinomial score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Explanation: The accuracy scores I've found for these 3 models is quite low at around 50-53%. I think further hyper-parameter (alpha)\n",
    "# tweaking needs to be performed to get these scores up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.5. Utilizing Pipeline and GridSearchCV, use 5 different alpha values to train a Bernoulli Naive Bayes and Multinomial Naive Bayes on the dataset. Print out the accuracy for each, and explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli best alpha: {'BernNB__alpha': 100.0}\n",
      "Bernoulli training score: 0.5776465600775194\n",
      "Bernoulli accuracy score for best model against Test Data: 0.5370705244122965\n",
      "\n",
      "\n",
      "Multinomial best alpha: {'MultiNB__alpha': 100.0}\n",
      "Multinomial training score: 0.5853682170542636\n",
      "Multinomial accuracy score with best model against Test Data: 0.5352622061482821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Normally would've had a preprocessing component, perhaps with LabelBinarizer, but it was already performed above.\n",
    "pipeline_multi = Pipeline(steps=[\n",
    "    ('MultiNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_bern = Pipeline(steps=[\n",
    "    ('BernNB', BernoulliNB()),\n",
    "])\n",
    "\n",
    "# Alphas to try out\n",
    "alphas = np.array([0.01, 0.1, 1, 10, 100])\n",
    "\n",
    "# Bernoulli grid search best params\n",
    "bern_grid = GridSearchCV(estimator=pipeline_bern, param_grid=dict(BernNB__alpha=alphas), cv=10)\n",
    "bern_grid.fit(X_train, y_train)\n",
    "y_pred_bern = bern_grid.predict(X_test)\n",
    "print(\"Bernoulli best alpha:\", bern_grid.best_params_)\n",
    "print(\"Bernoulli training score:\", bern_grid.best_score_)\n",
    "print(\"Bernoulli accuracy score for best model against Test Data:\", accuracy_score(y_test, y_pred_bern))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Multinomial grid search best params\n",
    "multi_grid = GridSearchCV(estimator=pipeline_multi, param_grid=dict(MultiNB__alpha=alphas), cv=10)\n",
    "multi_grid.fit(X_train, y_train)\n",
    "y_pred_multi = multi_grid.predict(X_test)\n",
    "print(\"Multinomial best alpha:\", multi_grid.best_params_)\n",
    "print(\"Multinomial training score:\", multi_grid.best_score_)\n",
    "print(\"Multinomial accuracy score with best model against Test Data:\", accuracy_score(y_test, y_pred_multi))\n",
    "\n",
    "# It seems that tuning the alpha parameter allowed us to achieve a slightly higher accuracy score for both models.\n",
    "# From 51.3% to 53.7% for Bernoulli using an alpha of 100\n",
    "# From 53.3% to 53.5% for Multinomial using an alpha of 100\n",
    "# Prior to the hyper parameter tuning, Multinomial was the best model, but with modifying the alpha, Bernoulli is now the best model.\n",
    "# I increased the CV to 10 from 5 after experimenting with various amounts of folds and this seemed to be better than the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in Bayesian networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q.6. Create a new text cell in your Notebook: Complete a 50-100 word summary \n",
    "    (or short description of your thinking in applying this week's learning to the solution) \n",
    "     of your experience in this assignment. Include:\n",
    "                                                                      \n",
    "What was your incoming experience with this model, if any?\n",
    "what steps you took, what obstacles you encountered.\n",
    "how you link this exercise to real-world, machine learning problem-solving. (What steps were missing? What else do you need to learn?)\n",
    "This summary allows your instructor to know how you are doing and allot points for your effort in thinking and planning, and making connections to real-world work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter summary here\n",
    "# No incoming experience. I'm not entirely sure why we had to use pipelines or what the expectation was in how to use it.\n",
    "# All of the guides online showed some preprocessing, but since I already did that above, it would've been redundant (I\n",
    "# mentioned this in the comments and how I would've approached it otherwise). An interesting note while I was playing\n",
    "# with this data was that the GridSearchCV gives a best score based on the training data and not accuracy scores against the\n",
    "# test data. I nearly presented the 'best_score_' as my accuracy, until I realized this. It makes sense why this happens\n",
    "# but the parameter name was misleading. The documentation says, \"Mean cross-validated score of the best_estimator\".\n",
    "# I liked experimenting with various parameters to discover how the data could yield different results-- which is very\n",
    "# real world in my opinion. I think steps that were missing from this assignment was further clarification on what\n",
    "# we needed to do with the 'Pipeline' class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}